{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 2 - Stemming and Part of Speech Tagging with NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today we will build upon what we learned last week concerning frequency distributions to utilize stemming and part of speech (POS) taggers.\n",
    "\n",
    "Stemming is the process for reducing words to their word stem, base or root form. For example, the result of stemming the words “kicker,” “kicked” and “kicking” is “kick.” \n",
    "\n",
    "The process of classifying words into their parts of speech and labeling them accordingly is known as part-of-speech tagging, POS-tagging, or simply tagging. Parts of speech are also known as word classes or lexical categories. The collection of tags used for a particular task is known as a tagset. \n",
    "\n",
    "A part-of-speech tagger, or POS-tagger, processes a sequence of words, and attaches a part of speech tag to each word. \n",
    "\n",
    "We’ll be tagging words in the input file as these types of nouns, among other tags:\n",
    "\n",
    "- NN: Noun, singular or mass\n",
    "- NNP: Proper noun, singular\n",
    "- NNS: Noun, plural\n",
    "- NNPS: Proper noun, plural\n",
    "\n",
    "You can find a comprehensive list of POS abbrevations and their meanings here: (https://cs.nyu.edu/grishman/jet/guide/PennPOS.html). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminary Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk \n",
    "from nltk.corpus import stopwords\n",
    "from nltk import FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = open('input.txt','r')\n",
    "raw = f.read()\n",
    "raw = raw.replace('\\n',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Tokenization\n",
    "tokens = nltk.word_tokenize(raw)\n",
    "\n",
    "#Stopwords Removal and only keep text data then change to lowercase\n",
    "mystopwords = stopwords.words('english')\n",
    "words = [w.lower() for w in tokens if w.isalpha() if w.lower()not in mystopwords]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Porter Stemmer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Use Porter Stemmer \n",
    "porter = nltk.PorterStemmer()\n",
    "stem1 = [porter.stem(w) for w in words]\n",
    "\n",
    "#Encode with utf-8\n",
    "stem1 = [w.encode('utf8') for w in stem1]\n",
    "\n",
    "#Get the frequency distribution \n",
    "freq1 = FreqDist(stem1)\n",
    "#Sort the result\n",
    "sorted_freq1 = sorted(freq1.items(),key = lambda k: k[1], reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sorted_freq1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "freq1.plot(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.Lancaster Stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Steps are the same with the Porter Stemmer\n",
    "lancaster = nltk.LancasterStemmer()\n",
    "stem2 = [lancaster.stem(w) for w in words]\n",
    "stem2 = [w.encode('utf8') for w in stem2]\n",
    "freq2 = FreqDist(stem2)\n",
    "sorted_freq2 = sorted(freq2.items(),key = lambda k: k[1], reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sorted_freq2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "freq2.plot(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.WordNet Lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Steps are the same with the previous two stemmers \n",
    "wnl = nltk.WordNetLemmatizer()\n",
    "stem3 = [lancaster.stem(w) for w in words]\n",
    "stem3 = [w.encode('utf8') for w in stem3]\n",
    "freq3 = FreqDist(stem3)\n",
    "sorted_freq3 = sorted(freq3.items(),key = lambda k: k[1], reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sorted_freq3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "freq3.plot(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#write result into .txt file\n",
    "with open('stemming_output.txt','w') as f:\n",
    "    for word, frequency in sorted_freq1: #here you can change to sorted_freq2 or 3 \n",
    "        f.write(str(word)+'\\t'+str(frequency)+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part of Speech Tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- NN: Noun, singular or mass\n",
    "- NNP: Proper noun, singular\n",
    "- NNS: Noun, plural\n",
    "- NNPS: Proper noun, plural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "POS_tags = nltk.pos_tag(tokens) #use unprocessed 'tokens', not 'words'\n",
    "\n",
    "#Generate a list of POS tags\n",
    "POS_tag_list = [(word,tag) for (word,tag) in POS_tags if tag.startswith('N')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Generate a frequency distribution of all the POS tags\n",
    "tag_freq = nltk.FreqDist(POS_tag_list)\n",
    "#Sort the result \n",
    "sorted_tag_freq = sorted(tag_freq.items(), key = lambda k:k[1], reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sorted_tag_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tag_freq.plot(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#write result into .txt file\n",
    "with open('POS_output.txt','w') as f:\n",
    "    for (word,tag),frequency in sorted_tag_freq:\n",
    "        f.write(str(word)+'\\t'+str(tag)+'\\t'+str(frequency)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}